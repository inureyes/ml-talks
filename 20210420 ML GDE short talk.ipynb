{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Distributed TensorFlow: Scale-up your model training\n",
    "## Jeongkyu Shin\n",
    "\n",
    "Prepared for ML GDE talk. (2021 Apr.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jeongkyu Shin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Lablup Inc.: Make AI Accessible\n",
    "     * Making Backend.AI.\n",
    "     * Incredibly convenient ```open source``` machine learning cluster platform\n",
    "\n",
    "* Google Developers Experts\n",
    "     * ML / DL GDE (Context retrieval)\n",
    "   \n",
    "* I like to play with open source. For a long time.\n",
    "     * Hobby becomes Research, Research becomes Job.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](slides/Picture2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image](slides_en/Slide3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![image](slides_en/Slide10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides_en/Slide11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Super simple example\n",
    "\n",
    "Below is a very, very simple MNIST example.\n",
    "\n",
    "Today, we're going to refine this example and look at the process of converting it to distributed training code.\n",
    "\n",
    "First, let's build a basic data load and model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mnist.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def mnist_dataset(batch_size):\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "  x_train, x_test = x_train / np.float32(255), x_test / np.float32(255)\n",
    "  y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
    "\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "      (x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "      (x_test, y_test)).batch(batch_size)\n",
    "  return train_dataset, test_dataset\n",
    "\n",
    "def build_and_compile_cnn_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.Input(shape=(28, 28)),\n",
    "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ]) \n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "      metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Then, let's train simplest fashion MNIST model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "70/70 [==============================] - 6s 4ms/step - loss: 2.2836 - accuracy: 0.1976\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2.1921 - accuracy: 0.3999\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2.0860 - accuracy: 0.5190\n",
      "157/157 [==============================] - 2s 11ms/step - loss: 1.9907 - accuracy: 0.5404\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import mnist\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "## GPU allocation part (important!)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = mnist.mnist_dataset(batch_size)\n",
    "\n",
    "model = mnist.build_and_compile_cnn_model()\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=70)\n",
    "\n",
    "eval_loss, eval_acc = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We ran the basic Fashion MNIST model through tf.keras.\n",
    "\n",
    "Let's dive into distributed training world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why distributed training / processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Because training talks sooooo long time\n",
    "\n",
    "* BERT\n",
    "* T5\n",
    "* GPT-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides/Slide7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides/Slide8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides/Slide9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides_en/Slide15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " * Training needs to be faster.\n",
    "    * The more distributing, the faster training\n",
    "\n",
    " * Less extra effort is required.\n",
    "    * Code modifications should be minimized.\n",
    "\n",
    " * It should be reproducible.\n",
    "    * System dependencies should be low.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides_en/Slide16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](slides/Slide10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Support for distributed processing of TensorFlow\n",
    "\n",
    "* Strategy-based support (1.12~)\n",
    "   * Distributed processing is supported by calling a predefined strategy.\n",
    "\n",
    "* tf.data based pipeline parallelization\n",
    "   * Data pipeline parallelization\n",
    "   * Useful when there are traffic restrictions by data source\n",
    "\n",
    "* Mesh TensorFlow\n",
    "   * In case of distributed model training with multiple nodes\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## tf.distribute.strategy\n",
    "\n",
    "* goal\n",
    "   * Convenient use\n",
    "   * Powerful performance\n",
    "   * Easy strategy replacement\n",
    "\n",
    "* General decentralization policy\n",
    "   * MirroredStrategy\n",
    "   * CentralStorageStrategy\n",
    "\n",
    "* Special case\n",
    "   * OneDeviceStrategy\n",
    "   * TPUStrategy\n",
    "   * ParameterServerStrategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tutorial: distributed processing on multi-node / multi-GPU systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* MirroredStrategy\n",
    "    * TensorFlow's default distributed processing policy\n",
    "    * All-reduce based\n",
    "    * Optimized for multi-GPU\n",
    "    * “Simple is the best”\n",
    "\n",
    "* MultiWorkerMirroredStrategy\n",
    "    * Apply MirrorStrategy in a multi-node environment\n",
    "    * It's a little slow, but simple is the best!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](slides/Picture1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Time is running out\n",
    "\n",
    "* We'll start right away with MultiWorkerMirroredStrategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MultiWorkerMirroredStrategy  \n",
    "  \n",
    "* Multi-node version of MirroredStrategy\n",
    "   * Internode communication becomes a bottleneck.\n",
    "   * Still, if the model is large, it will accelerate.\n",
    "   * It's hard to see the enhancement in MNIST, but it's obvious from ResNet.\n",
    "  \n",
    "* Implementation\n",
    "   * One of the nodes becomes the master node.\n",
    "   * Manage node information through cluster_resolver.\n",
    "   * gRPC, NCCL are used for communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MultiWorkerMirroredStrategy code execution\n",
    "\n",
    "* Action\n",
    "    * Determine node role based on the value set in TF_CONFIG in advance.\n",
    "    * Starting with TensorFlow 2, you can designate all nodes as Workers. (In the past, a separate master was designated and should be pointed out.)\n",
    "    * If all nodes are designated as Workers, the first worker becomes the master node.\n",
    "   \n",
    "* Master node\n",
    "    * The master node waits for all worker nodes to contact you in the Strategy Scope of MultiWorker MirroredStrategy.\n",
    "* Worker node\n",
    "    * Worker nodes register themselves to the master node in the scope during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting simple_worker_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile simple_worker_mnist.py\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import mnist\n",
    "\n",
    "per_worker_batch_size = 64\n",
    "\n",
    "## This is a necessary part only for manual cluster setup.\n",
    "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
    "num_workers = len(tf_config['cluster']['worker'])\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "global_batch_size = per_worker_batch_size * num_workers ## 수동 클러스터 설정시 필요한 부분입니다.\n",
    "multi_worker_dataset, test_dataset = mnist.mnist_dataset(global_batch_size)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Model building/compiling need to be within `strategy.scope()`.\n",
    "    multi_worker_model = mnist.build_and_compile_cnn_model()\n",
    "    multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)\n",
    "eval_loss, eval_acc = multi_worker_model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Create practical code for actually use\n",
    "\n",
    "* So far, these are some example codes.\n",
    "* Now let's look at the actual code.\n",
    "* Below is the code to put in a typical pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting practical_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile practical_mnist.py\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "## Initialize GPUs to be incremental memory reference mode\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "## Set the multi worker mirrored strategy\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "## Data load\n",
    "datasets, info = tfds.load(name='fashion_mnist', with_info=True, as_supervised=True)\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']\n",
    "\n",
    "#multi_worker_dataset = mnist.mnist_dataset(global_batch_size)\n",
    "\n",
    "## Set  input pipeline\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "print('\\nNumber of replicas in sync: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "### Normalize\n",
    "def scale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "  return image, label\n",
    "\n",
    "train_dataset = mnist_train.map(scale).take(num_train_examples).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
    "train_dataset.options().experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "eval_dataset.options().experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "## Setup functions\n",
    "# Function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5\n",
    "\n",
    "# Callback for printing the Learning Rate at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model.optimizer.lr.numpy()))\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "with strategy.scope():\n",
    "  # Model building/compiling need to be within `strategy.scope()`.\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "callbacks = [\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='/home/work/logs'),\n",
    "  tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                    save_weights_only=True),\n",
    "  tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "  PrintLR()\n",
    "]\n",
    "model.fit(train_dataset, epochs=12, callbacks=callbacks)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n",
    "# Model saving\n",
    "path = 'saved_model/'\n",
    "model.save(path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "%%writefile practical_mnist.py\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "## Initialize GPUs to be incremental memory reference mode\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "## Set the multi worker mirrored strategy\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "\n",
    "## Data load\n",
    "datasets, info = tfds.load(name='fashion_mnist', with_info=True, as_supervised=True)\n",
    "mnist_train, mnist_test = datasets['train'], datasets['test']\n",
    "\n",
    "#multi_worker_dataset = mnist.mnist_dataset(global_batch_size)\n",
    "\n",
    "## Set  input pipeline\n",
    "num_train_examples = info.splits['train'].num_examples\n",
    "num_test_examples = info.splits['test'].num_examples\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "print('\\nNumber of replicas in sync: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "### Normalize\n",
    "def scale(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image /= 255\n",
    "  return image, label\n",
    "\n",
    "train_dataset = mnist_train.map(scale).take(num_train_examples).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
    "train_dataset.options().experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "eval_dataset.options().experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "## Setup functions\n",
    "# Function for decaying the learning rate.\n",
    "# You can define any decay function you need.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5\n",
    "\n",
    "# Callback for printing the Learning Rate at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model.optimizer.lr.numpy()))\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "with strategy.scope():\n",
    "  # Model building/compiling need to be within `strategy.scope()`.\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "callbacks = [\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='/home/work/logs'),\n",
    "  tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                    save_weights_only=True),\n",
    "  tf.keras.callbacks.LearningRateScheduler(decay),\n",
    "  PrintLR()\n",
    "]\n",
    "model.fit(train_dataset, epochs=12, callbacks=callbacks)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n",
    "# Model saving\n",
    "path = 'saved_model/'\n",
    "model.save(path, save_format='tf')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pipeline\n",
    "\n",
    "More serious for distributed training. Very simple pipeline from data download to training to serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This part saves checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Change learning rate dynamically.\n",
    "def decay(epoch):\n",
    "  if epoch < 3:\n",
    "    return 1e-3\n",
    "  elif epoch >= 3 and epoch < 7:\n",
    "    return 1e-4\n",
    "  else:\n",
    "    return 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load checkpoint and check the accuracy,\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
    "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n",
    "\n",
    "# Save mode as savedmodel format.\n",
    "path = 'saved_model/'\n",
    "model.save(path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Note: Replica size\n",
    "\n",
    "* When determining the batch size, you must pass the desired batch size multiplied by the number of workers.\n",
    "    * Otherwise, each node may be trained with overlapping datasets, and due to the nature of the all-reduce algorithm, you may see side effects such as overfitting.\n",
    "\n",
    "```python\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "print('\\nNumber of replicas in sync: {}'.format(strategy.num_replicas_in_sync))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Guides\n",
    "\n",
    "* https://www.tensorflow.org/tutorials/distribute/custom_training\n",
    "* https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras\n",
    "* https://www.tensorflow.org/tutorials/distribute/input\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you.\n",
    "\n",
    "It was so fast. Was it?\n",
    "\n",
    " * inureyes@gmail.com\n",
    " * Facebook: jeongkyu.shin\n",
    " * GitHub: inureyes\n",
    "\n",
    " * For more information, \n",
    "   * Lablup Inc: https://www.lablup.com\n",
    "   * Backend.AI: https://www.backend.ai\n",
    "   * GitHub    : https://github.com/lablup/backend.ai\n",
    "   * Backend.AI Cloud: https://cloud.backend.ai\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "TensorFlow 2.4 on Python 3.8 & CUDA 11.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
